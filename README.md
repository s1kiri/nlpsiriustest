Данные я получал из чата Тренировок по алгоритмам Яндекса https://t.me/+s7HAQFTWTGAwMmUy.  
Оттуда я скачал 30 мб данных, которые превратились в ~12 мб размеченных правильмы образом диалогов.  
small-версию я обучил на всем объёме данных(больше 6.000.000 символов) - файл dialogues.txt. Из за того, что мне не хватало мощностей для дообучения медиум модели на всём объеме данных, я обучал на сильно укороченной версии - cutted_dial.txt.  
Дообучал я через встроенный trainer из transformers. Телеграм-бот написан на aiogram и позволяет общаться с моделью с учетом контекста прошлых сообщений.  
Чат я выбрал довольно специфический, что было ошибкой с моей стороны, так как в чате по алгоритмам много необщеупотребительной лексики.  
Сами модели на гитхаб не влезли, в папках с моделями лежит txt, а в нем ссылка на гугл диск с моделями.  <br/>
Вот пример работы бота, ссылку на самого бота не даю, так как негде его хостить.  <br/>
![Image alt](https://github.com/s1kiri/nlpsiriustest/raw/main/пример.png)
